---
title: "아파치 Kafka for beginners[1]"
date: 2021-05-01T14:00:00+09:00
#Language, C++, DB, MsSQL, MySQL, Common, SCM, Perforce, Blog, SVN
categories:
- Common
- Kafka
#C++, Modern C++, DB, MsSQL, MySQL, Perforce, SVN, Git, GitHub, Management, Blog, Hugo, Architecture
tags:
- Kafka
keywords:
- tech
- developer
- 개발자
- programmer
- programming
- software
- 프로그래머
- coding
- 코딩
- server

#thumbnailImage: //example.com/image.jpgC스터디 내용작성 ㅇS이번 항이번 이버C++ 대ude
---

udemy의 Apache Kafka for absolute beginners 강좌를 수강하며, 리마인드 할 만한 부분을 정리하는 시리즈입니다.

<!--more-->

​    

## What you'll learn

- Apache Kafka Ecosystem, Components and Big Picture
- Kafka Architecture and Core Concepts
- Multi-node Confluent Community Kafka
- Kafka Storage Architecture in depth
- Kafka Cluster Architecture in depth
- Kafka Producer API Programming in Java
- Kafka Consumer API Programming in Java
- Idempotence and Transactions in Kafka
- JSON and AVRO Serialization
- Exactly Once Processing in Kafka



## Section 1 : Kafka Ecosystem - The Big Picture

### 1. What is Apache Kafka

- 아파치 카프카는 분산 스트리밍 플랫폼

  - 실시간 데이터 스트림 생성

  - 실시간 데이터 스트림 처리

- 대량의 실시간 데이터 생성 -> 카프카 서버 적재
  - 백앤드 서비스에서 카프카 서버에 적재된 데이터 활용

- 카프카는 Pub/Sub 메세징 시스템 아키텍쳐 채택

  - Publisher(Message Producer) -> Broker -> Subscriber(Message Consumer)
    * Broker : 프로듀서의 메세지를 수신하여 local storage에 저장

- History

  - 링크드인에서 오픈소스 프로젝트로 개발(2011)
  - 분산 처리 서비스가 커지고, 장비간 공유데이터 처리시 복잡도가(서버간 direct connection) 매우 증가 -> 이를 해결하기 위해 개발(데이터 통합 솔루션)

- 카프카의 요소

  - Kafka Broker : 중앙 서버 시스템 제공
  - kafka Client : 프로듀서와 컨슈머 API 제공

  - Kafka Connect : initial data integration problem for which Kafka was initially designed
  - Kafka Streams : creating real time extreme processing applications.
  - KSQL : aiming to become a real time database and capture some market sharing Databases and DW/BI space.



### 2. Apache Kafka Core Concepts

#### Producer

- 작은 조각의 메세지(array of bytes)를 생성하여 전송

#### Consummer

- 카프카 서버에 메세지 요청 -> 메세지 처리 -> 반복

#### Broker

- 브로커는 카프카 중앙 서버
- 메세지 적재, 전달 처리

#### Cluster

- 분산 처리 시스템에서 공통 목적을 갖는 컴퓨터들의 그룹
- 여러대의 Broker로 묶인 하나의 Cluster는 외부에서 볼 때 하나의 Instance로 동작

#### Topic

- 메세지의 타입
- 메세지들은 Topic으로 그룹화 됨

#### Topic Partitions

- 대용량 메세지를 처리 하기 위해(storage capacity problem) 브로커 클러스터는 토픽을 파티셔닝 하여 여러 장치에 분산 저장함
- 카프카 브로커는 토픽당 몇개 파티션으로 처리 할 지 상관하지 않음
- 토픽 생성시 사용자(개발자가 토픽의 파티션수를 디자인(결정)
- 파티셔닝은 저장소 용량 문제 해결을 위한 것 뿐 아니라, 워크로드의 분산처리 목적이 더 중요

#### Partition offset

- 파티션 안에서 브로커에 의해 각 메세지에 부여된 유니크한 순차 부여된 ID (도착 순서 보장)
- no global ordering, 각 파티션 내부에 한정된 순서

#### Consumer Group

- 컨슈머를 그룹으로 묶을 수 있음
- 워크로드 분할을 위해
- 초당 처리량 향상(컨슈머 클러스터링)

  

### 3. Kafka Connect Core Concepts

- 브로커와 통신( writing / reading) 을 전담하는 인스턴스, 직접 이 부분을 담당하는 서버를 구현해도 되지만 Connect가 그 역할을 할 수 있음

- 브로커에게 Producing된 데이터를 전달하는 역할만 전담 할 수 있음 (Source Connector)
- 브로커로부터 데이터를 Consume하는 역할만 전담 할 수 있음 (Sink Connector)
- Java API로 제공
- 확장성 있음(클러스터링 가능, 로드 밸런싱, fault tolerant)




### 4. Kafka Streams Core Concepts

### 5. Kafka SQL Core Concepts

### 6. When to use What?

